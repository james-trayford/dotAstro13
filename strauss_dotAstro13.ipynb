{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5014193-c2b7-4c3e-93a1-0b040e036e7e",
   "metadata": {},
   "source": [
    "Notebook prepared by **Dr James Trayford** - for queries please email [`james.trayford@port.ac.uk`](mailto:james.trayford@port.ac.uk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df294e0-bbce-4654-916c-3e1b0ef6893a",
   "metadata": {},
   "source": [
    "To use this notebook (if you haven't already) you can first save a copy to your local drive by clicking `File > Save a Copy in Drive` and run on that copy. `Edit > Clear all outputs` on that copy should also ensure you have a clean version to start from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c982dd6-334b-4dc7-ba7c-9ab8724ea8bc",
   "metadata": {},
   "source": [
    "# **.Astronomy 13** - üîäüé∂üéµ Sonification of data with `strauss` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f166839e-8300-405a-8699-7ea368b9a01c",
   "metadata": {},
   "source": [
    "In this notebook, I've tried to make the different examples stand-alone so you can run and re-run cells out of order once you've got the data. This means repeating code between cells. To give some hints at what you might want to edit in these examples, I've added comments and the \"‚úèÔ∏è\" symbol \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c79a43c-3aeb-4afd-8db8-c159535dc794",
   "metadata": {},
   "source": [
    "first, let's install the `strauss` code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60330dfe-93c7-40ad-a4ac-c502b18299e3",
   "metadata": {},
   "outputs": [],
   "source": [
    " !pip install --quiet git+https://github.com/james-trayford/strauss.git@spectraliser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66276559-7de7-493a-b406-ad5f21d2fe88",
   "metadata": {},
   "source": [
    "*We will use the `spectraliser` development branch for this notebook. Install can take a while - but you should only need to run it once!*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e64c89-2946-4d6c-bfb3-6e35684fe327",
   "metadata": {},
   "source": [
    "We'll also grab the repository from _GitHub_ for easy access to some files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27502abf-acfc-4cef-aba0-2796a0e4a6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    " !git clone https://github.com/james-trayford/strauss.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b08ddb1-d6a4-474f-9f7a-f752e58c6845",
   "metadata": {},
   "source": [
    "Now, let's import the modules we need..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425800d-ca2f-47a1-977a-273e41234c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload \n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from strauss.sonification import Sonification\n",
    "from strauss.sources import Objects, Events\n",
    "from strauss import channels\n",
    "from strauss.score import Score\n",
    "from strauss.generator import Synthesizer, Spectralizer\n",
    "from strauss import sources as Sources\n",
    "\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# modules to display in-notebook\n",
    "import IPython.display as ipd\n",
    "from IPython.display import display, Markdown, Latex, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0767b88-937e-460a-8895-7bb8f153a32e",
   "metadata": {},
   "source": [
    "## Section 0 : Prepare Data _(optional!)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa6e00c-4d19-4f6f-9e7d-a8b8d6b91c6f",
   "metadata": {},
   "source": [
    "‚ö†  ***The cells in this section show how data was downloaded and prepared for completeness. You can skip to Section 1 to download the data directly and avoid `lightkurve` install*** ‚ö†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef8bb4-4e22-437c-afdb-495d48caf926",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightkurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066c9ae-d834-4d76-b1be-a6576beec082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from lightkurve import search_targetpixelfile, search_lightcurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71369f80-f779-4be3-ab63-ec6b2fdb9195",
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = ['RR Lyra', \"Kepler-2\", '55 Cancri', 'TYC 8998-760-1', 'HR 8799', 'AB Pictoris']\n",
    "curve = [0, 30, 7, 1, -1, -3]\n",
    "\n",
    "if not os.path.isdir('prepared_data'):\n",
    "    path = os.path.realpath(\"prepared_data\")\n",
    "    if not glob.glob(path):\n",
    "      os.mkdir(path)\n",
    "        \n",
    "for i in range(len(objs)):\n",
    "    tab = search_lightcurve(objs[i])\n",
    "    lc = tab[curve[i]].download().remove_nans().remove_outliers()\n",
    "    pg = lc.to_periodogram()\n",
    "    \n",
    "    t = np.array(lc.time.value.astype(float))\n",
    "    fl = np.array(lc.flux.value)\n",
    "    frq = 1/np.array(pg.period.value)\n",
    "    p = np.array(pg.power.value)\n",
    "    \n",
    "    tag = objs[i].replace(\" \", \"\")\n",
    "    \n",
    "    np.savetxt(f\"prepared_data/{tag}_lc.dat\",\n",
    "                np.array(np.column_stack([t,fl])))\n",
    "    np.savetxt(f\"prepared_data/{tag}_psd.dat\", \n",
    "               np.array(np.column_stack([frq,p])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e6562-7554-4e76-9be1-5cb10c14f294",
   "metadata": {},
   "source": [
    "## Section 1 - Getting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4bdad-0099-4c7b-94a5-948b56dbec13",
   "metadata": {},
   "source": [
    "‚ö†  ***The cells in this section are to organise the data we need for the session, don't worry too much about the details of the code here!*** ‚ö†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0fdcee-49d2-4a4a-b79f-f975a9603876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import urllib\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c71dbbf-9a9e-4e6f-af76-a27db09d212f",
   "metadata": {},
   "source": [
    "We download and unpack the data used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c780bd9-edbf-4972-bd8f-b739b7af7a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't bother if the directory already exists (i.e. Section 0 was run)\n",
    "if os.path.isdir('prepared_data'):\n",
    "    outdir = \"./prepared_data\"\n",
    "\n",
    "    path = os.path.realpath(outdir)\n",
    "    if not glob.glob(outdir):\n",
    "      os.mkdir(path)\n",
    "\n",
    "    fname = \"dotAstro13_STRAUSS_tutorial.zip\"\n",
    "    url = \"https://drive.google.com/uc?export=download&id=1sXesBtj2DE1fyThay8EX6l87H9cDz0-h\"\n",
    "    print(f\"Downloading files...\")\n",
    "\n",
    "    with urllib.request.urlopen(url) as response, open(f\"{path}/{fname}\", 'wb') as out_file:\n",
    "      data = response.read() # a `bytes` object\n",
    "      out_file.write(data)\n",
    "\n",
    "    print(f\"Unzipping files to {outdir}/ ...\")\n",
    "    with zipfile.ZipFile(f\"{outdir}/{fname}\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(f\"{outdir}\")\n",
    "\n",
    "    print(f\"Clearing up...\")\n",
    "    os.remove(f\"{path}/{fname}\")\n",
    "\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed37aa-4fcd-4f35-8407-f408564f726a",
   "metadata": {},
   "source": [
    "First, we organise the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8b7a8c-92d2-465d-b451-269052d067df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = {}\n",
    "psd = {}\n",
    "\n",
    "for f in glob.glob('prepared_data/variable_stars/*_lc.dat'):\n",
    "    tag = f.split(os.sep)[-1].split('_')[0]\n",
    "    lc[tag] = np.genfromtxt(f)\n",
    "    psd[tag] = np.genfromtxt(f'prepared_data/variable_stars/{tag}_psd.dat')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519d367d-4f2f-496d-ac70-bd1cb76f95d4",
   "metadata": {},
   "source": [
    "Define a useful function for plotting these lightcurves as we deal with them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516a9974-ad00-4afb-b65f-15efe856d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lightcurve(name, plot_type='scatter', truncate_index=None): \n",
    "    x = lc[name][:N,0]-lc[name][:N,0].min()\n",
    "    y = lc[name][:N,1]\n",
    "\n",
    "    if plot_type == 'scatter':\n",
    "        plt.scatter(x, y, s=4)\n",
    "    if plot_type == 'line':\n",
    "        plt.plot(x, y)\n",
    "        \n",
    "    plt.ylabel('Flux')\n",
    "    plt.xlabel('Time [days]')\n",
    "    plt.title(name)\n",
    "    plt.show()\n",
    "    return x, y "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e739c7-b829-47b2-a697-2857f758bce4",
   "metadata": {},
   "source": [
    "Show what targets we've got..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddbb919-3db7-4bc9-a6fa-79823918be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = list(psd.keys())\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4da8405-6740-41f8-a900-9b8cacc01e99",
   "metadata": {},
   "source": [
    "...and pick which we're going to sonify using the different variations below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84279391-1161-4859-b2ab-5820375b8842",
   "metadata": {},
   "outputs": [],
   "source": [
    "targlist = ['55Cancri'] # Pick an object or iterate through all 'targets'  ‚úèÔ∏è\n",
    "#targlist = targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67174ec3-d9a9-472b-9a59-f991caf86dae",
   "metadata": {},
   "source": [
    "Now, we are ready iterate through target light-curves to sonify them, alongside their plots!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c36fe5b-25c3-4f86-ae65-0ca472e2d802",
   "metadata": {},
   "source": [
    "## Section 2 - One-dimensional data series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323e690c-ab4d-40b4-b157-63a86329b0bf",
   "metadata": {},
   "source": [
    "Let's consider the simple case of one-dimensional data series. In these examples, we have light-curves and periodograms from a number of diverse variable stars. How can we go about sonifying them?\n",
    "\n",
    "Here we will sonify light-curves as a ***one-dimensional time series*** , where some ***sound property*** is is varied with ***time*** in the ***sonification***, in the same way that **flux**, varies with ***observation time*** in a ***light-curve*** (early in the sonification is shorter wavelengths, later is longer wavelengths)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db965de7-bc03-41bf-aa51-becb9bc03532",
   "metadata": {},
   "source": [
    "### Section 2.1 - Event sonification vs Scatter Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f1edb3-5ab8-473e-ad60-2bf6bfeb13cc",
   "metadata": {},
   "source": [
    "In `strauss` we could treat each ***flux density*** data point in the spectra as separate audio `Events`, with an occurence `time` mapped from their ***wavelength***.\n",
    "\n",
    "However, articulating each data point as a separate ***note*** for ***many thousands*** of data points can require long and drawn-out sonifications.\n",
    "\n",
    "Here we demonstrate this approach with just a portion of the data points (staying within `Colab`'s RAM limitations for unpaid users ü§´). We use the `Synthesizer` object with the `pitch_mapper` preset by default - this has a default pitch range of ***two octaves*** (a factor of 4 in frequency) and we pick an `E3` note (165 Hz) as the base (lowest) frequency.\n",
    "\n",
    "We will hear the **flux** of each point as `pitch`, with their observation mapped to the occurence `time` (moving from low to high wavelength). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e738f-bee3-40ae-a422-aebd4f8139a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set an index to trunate the lightcurve (if it's too long...)\n",
    "N = 950\n",
    "#N = None\n",
    "\n",
    "\n",
    "for trg in targlist: # iterate, if you like\n",
    "    \n",
    "    x,y = show_lightcurve(trg, plot_type='scatter', truncate_index=N)\n",
    "    \n",
    "    # specify the base notes used. In this example we use a single E3 note and\n",
    "    # freely vary the pitch via the 'pitch_shift' parameter\n",
    "    notes = [[\"E3\"]]\n",
    "    \n",
    "    # we could also just specify a particular frequency... ‚úèÔ∏è\n",
    "    # notes = [[150.]]\n",
    "    \n",
    "    score =  Score(notes, 15)\n",
    "    \n",
    "    maps = {'pitch':np.ones(x.size),\n",
    "            'time': x,\n",
    "            'pitch_shift':y}\n",
    "    \n",
    "    # specify audio system (e.g. mono, stereo, 5.1, ...)\n",
    "    system = \"mono\"\n",
    "    \n",
    "    # set up synth (this generates the sound using mathematical waveforms)\n",
    "    generator = Synthesizer()\n",
    "    generator.load_preset('pitch_mapper')\n",
    "    \n",
    "    # or maybe the sampler instead by uncommenting this block (this uses recorded audio clips)\n",
    "    # generator = Sampler(sampfiles=\"./strauss/data/samples/mallets\")\n",
    "    \n",
    "    generator.modify_preset({'note_length':0.1,\n",
    "                             'volume_envelope': {'use':'on',\n",
    "                                                 # A,D,R values in seconds, S sustain fraction from 0-1 that note\n",
    "                                                 # will 'decay' to (after time A+D)\n",
    "                                                 'A':0.02,    # ‚úèÔ∏è for such a fast sequence, using ~10 ms values\n",
    "                                                 'D':0.02,    # ‚úèÔ∏è for such a fast sequence, using ~10 ms values\n",
    "                                                 'S':0.,      # ‚úèÔ∏è decay to volume 0\n",
    "                                                 'R':0.001}}) # ‚úèÔ∏è for such a fast sequence, using ~10 ms values\n",
    "    \n",
    "    # set 0 to 100 percentile limits so the full pitch range is used...\n",
    "    # setting 0 to 101 for pitch means the sonification is 1% longer than the final note position\n",
    "    lims = {'time': ('0','101'),\n",
    "            'pitch_shift': ('0','100')}\n",
    "    \n",
    "    # set up source\n",
    "    sources = Events(maps.keys())\n",
    "    sources.fromdict(maps)\n",
    "    sources.apply_mapping_functions(map_lims=lims)\n",
    "    \n",
    "    soni = Sonification(score, sources, generator, system)\n",
    "    soni.render()\n",
    "    # soni.save('pitchpm.wav')\n",
    "    dobj = soni.notebook_display(show_waveform=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fde33ff-328e-4e57-be9a-741b2e01eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set an index to trunate the lightcurve (if it's too long...)\n",
    "N = 950\n",
    "#N = None\n",
    "\n",
    "for trg in targlist: # iterate, if you like\n",
    "    \n",
    "    x,y = show_lightcurve(trg, plot_type='scatter', truncate_index=N)\n",
    "    \n",
    "    # specify the notes used.\n",
    "    # C major pentatonic\n",
    "    notes = [[\"C3\",\"E3\",\"F3\",\"G3\",\"B3\",\"C4\",\"E4\",\"F4\",\"G4\",\"B4\",\"C5\",\"E5\",\"F5\",\"G5\",\"B5\"]]\n",
    "    \n",
    "    # or a whole-tone scale, (was it just a dream... a dream... a dream...)\n",
    "    #\n",
    "    # This is a \"symmetrical\" scale and here also demonstrates using raw frequencies in Hz.\n",
    "    # The whole tone scale uses 2 semitone jumps, what about minor thirds (3) fourths (5)\n",
    "    # or fifths (7)? Specify `semitones` to change this.\n",
    "    # `nint` specifies the number of intervals in the scale. Note a bigger semitone interval\n",
    "    # will reach higher pitches (perhaps inaudible ones...) ‚úèÔ∏è\n",
    "    \n",
    "    # semitones = 2.\n",
    "    # nint = 10\n",
    "    # notes = [100*2**(np.arange(nint)*(semitones/12))]\n",
    "    \n",
    "    # ------\n",
    "    # In this context, we also consider the `Score` optional parameter `pitch_binning`.\n",
    "    #\n",
    "    # This determines how we bin the 'pitch' quantity, which can be either:\n",
    "    # - 'uniform':  the range of mapped values for 'pitch' are split into even bins\n",
    "    #               representing  each of the scored notes\n",
    "    # - 'adaptive': the range of mapped values for 'pitch' split by percentile.\n",
    "    #               such that each interval is played approximately the same number of\n",
    "    #               times\n",
    "    # without specifying,  'adaptive' is used by default, but we specify 'uniform' here\n",
    "    #\n",
    "    # which is better for representing this data?\n",
    "    \n",
    "    # we specify 'uniform' pitch binning in the primary example... ‚úèÔ∏è\n",
    "    score =  Score(notes, 15, pitch_binning='uniform')\n",
    "    \n",
    "    # what about adaptive?\n",
    "    #score =  Score(notes, 15, pitch_binning='adaptive')\n",
    "    \n",
    "    maps = {'pitch':y,\n",
    "            'time': x}\n",
    "    \n",
    "    # specify audio system (e.g. mono, stereo, 5.1, ...)\n",
    "    system = \"mono\"\n",
    "    \n",
    "    # set up synth (this generates the sound using mathematical waveforms)\n",
    "    generator = Synthesizer()\n",
    "    generator.load_preset('pitch_mapper')\n",
    "    \n",
    "    generator.modify_preset({'note_length':0.15,\n",
    "                             'volume_envelope': {'use':'on',\n",
    "                                                 # A,D,R values in seconds, S sustain fraction from 0-1 that note\n",
    "                                                 # will 'decay' to (after time A+D)\n",
    "                                                 'A':0.02,    # ‚úèÔ∏è for such a fast sequence, using ~10 ms values\n",
    "                                                 'D':0.02,    # ‚úèÔ∏è for such a fast sequence, using ~10 ms values\n",
    "                                                 'S':1.,      # ‚úèÔ∏è decay to volume 0\n",
    "                                                 'R':0.001}}) # ‚úèÔ∏è for such a fast sequence, using ~10 ms values\n",
    "    \n",
    "    # set 0 to 100 percentile limits so the full pitch range is used...\n",
    "    # setting 0 to 101 for pitch means the sonification is 1% longer than\n",
    "    # the time needed to trigger each note - by making this more than 100%\n",
    "    # we give all the notes time to ring out (setting this at 100% means\n",
    "    # the final note is triggered at the momement the sonification ends)\n",
    "    lims = {'time': ('0','101'),\n",
    "            'pitch_shift': ('0','100'),\n",
    "            'pitch': ('0','100')}\n",
    "    \n",
    "    # set up source\n",
    "    sources = Events(maps.keys())\n",
    "    sources.fromdict(maps)\n",
    "    sources.apply_mapping_functions(map_lims=lims)\n",
    "    \n",
    "    soni = Sonification(score, sources, generator, system)\n",
    "    soni.render()\n",
    "    dobj = soni.notebook_display(show_waveform=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6cd57e-3b93-4cba-9f32-24a32ef4b13a",
   "metadata": {},
   "source": [
    "The articulation of each note lets you hear each data point separately, but over many noisy data points can lead to a confusing result - it's hard to keep track of the fluxes and our pitch memory is challenged.\n",
    "\n",
    "Instead we can try ***smoothly evolving*** parameters, designating the spectra as an ***evolving `Object`*** source class. We demonstrate this in the following subsection `3.1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d072603-8e70-4f71-90d0-60d5fb9b8d39",
   "metadata": {},
   "source": [
    "### Section 2.2: Object Sonification vs Line Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383b87c9-919d-4050-8816-0a195ee2d1ff",
   "metadata": {},
   "source": [
    "Let's first try the evolving Object approach without truncating the raw data in any way. In analogy to visual display, the Event representation is like plotting the spectrum as a scatter plot, while an Object representation is like plotting the spectrum as a continuous line.\n",
    "\n",
    "let's hear the 1D time-series data sonification, mapping flux density to pitch for the spectrum.\n",
    "\n",
    "*NB: If you were wondering why `strauss` refers to the varying pitch mapping as `pitch_shift` and not just `pitch`, this is because all sources in `strauss` also need a base `pitch` which is chosen from the `'notes'` structure (here always `'A2'`) by the `Score`. This is because `strauss` can play many sources at the same time! Again, you can read more about this [in the docs](https://strauss.readthedocs.io/en/latest/).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35280f38-553e-42a2-8f99-d00ae4f12dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # show spectrum again, for reference\n",
    "# display(Image(spectra_plots[stype][slabel]))\n",
    "\n",
    "for trg in targlist: # iterate, if you like  \n",
    "    # set an index to truncate the lightcurve (if it's too long...)\n",
    "    N = None\n",
    "    x,y = show_lightcurve(trg, plot_type='line')\n",
    "\n",
    "    notes = [[\"A2\"]]\n",
    "    score =  Score(notes, 15)\n",
    "    \n",
    "    # set up synth (this generates the sound using mathematical waveforms)\n",
    "    generator = Synthesizer()\n",
    "    generator.preset_details('pitch_mapper')\n",
    "    generator.load_preset('pitch_mapper')\n",
    "    \n",
    "    \n",
    "    data = {'pitch':1.,\n",
    "            'time_evo':x,\n",
    "            'pitch_shift':y}\n",
    "    \n",
    "    # set 0 to 100 percentile limits so the full pitch and time range is used...\n",
    "    lims = {'time_evo': ('0','100'),\n",
    "            'pitch_shift': ('0','100')}\n",
    "    \n",
    "    # set up source\n",
    "    sources = Objects(data.keys())\n",
    "    sources.fromdict(data)\n",
    "    sources.apply_mapping_functions(map_lims=lims)\n",
    "    \n",
    "    soni = Sonification(score, sources, generator, system)\n",
    "    soni.render()\n",
    "    dobj = soni.notebook_display(show_waveform=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef52d6c-ce73-4c5a-a33a-4500baedb4ea",
   "metadata": {},
   "source": [
    "How about mapping a low-pass filter to flux density?\n",
    "\n",
    "*using a 'tonal' carrier, uncomment line for a 'textural' (or white noise) carrier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a41bd4-67ed-4b97-8ffb-88848d5359dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trg in targlist: # iterate, if you like\n",
    "\n",
    "    # set an index to trucnate the lightcurve (if it's too long...)\n",
    "    N = None\n",
    "    x,y = show_lightcurve(trg, plot_type='line', truncate_index=N)\n",
    "    \n",
    "    generator = Synthesizer()\n",
    "    generator.modify_preset({'filter':'on'})\n",
    "    \n",
    "    # uncomment these lines to try a 'textural' sonification using white noise! ‚úèÔ∏è\n",
    "    # generator.load_preset('windy')\n",
    "    # generator.preset_details('windy')\n",
    "    \n",
    "    # we use a 'chord' here to create more harmonic richness (stacking fifths)...\n",
    "    notes = [[\"A2\", \"E3\", 'B3', 'F#4']]\n",
    "    score =  Score(notes, 15)\n",
    "    \n",
    "    data = {'pitch':[0,1,2,3],\n",
    "            'time_evo':[x]*4,\n",
    "            'cutoff':[y]*4}\n",
    "    \n",
    "    lims = {'time_evo': ('0','100'),\n",
    "            'cutoff': ('0','100')}\n",
    "    \n",
    "    # set up source\n",
    "    sources = Objects(data.keys())\n",
    "    sources.fromdict(data)\n",
    "    plims = {'cutoff': (0.15,0.95)}\n",
    "    sources.apply_mapping_functions(map_lims=lims, param_lims=plims)\n",
    "    \n",
    "    soni = Sonification(score, sources, generator, system)\n",
    "    soni.render()\n",
    "    dobj = soni.notebook_display(show_waveform=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ff41c-108f-4e21-84cd-2a83d75a45b8",
   "metadata": {},
   "source": [
    "In fact, there are many expressive properties of sound we could use to represent the data in a similar way. In `strauss` these are referred to as `mappable` properties.\n",
    "\n",
    "A subset of these can be used as an evolving property with the `Object` source class. These are referred to as `evolvable` properties.\n",
    "\n",
    "Lets show what's available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75277149-0ce4-483a-b8d3-8f22416cd267",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"### ***'Mappable'*** properties:\"))\n",
    "for m in Sources.mappable:\n",
    "  display(Markdown(f' * `{m}` '))\n",
    "\n",
    "display(Markdown(f\"### ***'Evolvable'*** properties:\"))\n",
    "for m in Sources.evolvable:\n",
    "  display(Markdown(f' * `{m}` '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e1aec6-7949-4228-adb0-618292c0d8e1",
   "metadata": {},
   "source": [
    "We can play around with some of these `evolvable` properties here. Are all of these effective for this data? Could they be effective for other types of data representations?\n",
    "\n",
    "The `idx` variable below controls which evolvable property is selected from the `some_mappings` list. `idx` can be changed to a number from 0 to 5 inclusive to choose a certain sound parameter from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fa0d51-79a1-4db9-badf-fdb3f18e3bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for trg in targlist: # iterate, if you like\n",
    "\n",
    "    # set an index to trunate the lightcurve (if it's too long...)\n",
    "    N = None\n",
    "    x,y = show_lightcurve(trg, plot_type='line', truncate_index=N)\n",
    "    \n",
    "    # A list of some 'evolvable' mappings\n",
    "    some_mappings = [\"volume\",\n",
    "                     \"azimuth\",\n",
    "                     \"volume_lfo/amount\",\n",
    "                     \"volume_lfo/freq_shift\",\n",
    "                     \"pitch_lfo/amount\",\n",
    "                     \"pitch_lfo/freq_shift\"]\n",
    "    \n",
    "    # change this (between 0 and 5) to select a different property to map...\n",
    "    idx = 0\n",
    "    \n",
    "    # use a stereo system to allow 'phi' mapping (low pan left and high pan right)\n",
    "    system = \"stereo\"\n",
    "    \n",
    "    display(Markdown(f\"### Sonifying in 1D using `evolvable` property - ***`{some_mappings[idx]}`***:\"))\n",
    "    \n",
    "    generator = Synthesizer()\n",
    "    generator.modify_preset({'filter':'on',\n",
    "                             \"pitch_hi\":-1, \"pitch_lo\": 1,\n",
    "                             \"pitch_lfo\": {\"use\": \"on\",\n",
    "                                           \"amount\":1*(\"pitch_lfo/freq_shift\" == some_mappings[idx]),\n",
    "                                           \"freq\":3*5**(\"pitch_lfo/freq_shift\" != some_mappings[idx]),\n",
    "                                           \"phase\":0.25},\n",
    "                             \"volume_lfo\": {\"use\": \"on\",\n",
    "                                            \"amount\":1*(\"volume_lfo/freq_shift\" == some_mappings[idx]),\n",
    "                                            \"freq\":3*5**(\"volume_lfo/freq_shift\" != some_mappings[idx]),\n",
    "                                            \"phase\":0}\n",
    "                            })\n",
    "    \n",
    "    # try a different chord (stacking fifths)...\n",
    "    notes = [[\"A2\",\"E3\",\"B4\",\"F#4\"]]\n",
    "    \n",
    "    # chords and can also be specified via chord names and base octave....\n",
    "    # notes = \"Em6_3\"\n",
    "    \n",
    "    \n",
    "    score =  Score(notes, 15)\n",
    "    \n",
    "    data = {'pitch':[0,1,2,3],\n",
    "            'time_evo':[x]*4,\n",
    "            'cutoff':[0.9]*4,\n",
    "            'polar':[0.5]*4,\n",
    "            some_mappings[idx]:[(y-y.min())/(y.max()-y.min())]*4}\n",
    "    \n",
    "    lims = {'time_evo': ('0','100'),\n",
    "            \"volume\": ('0','100'),\n",
    "            \"azimuth\": (-0.5,1.5),\n",
    "            \"volume_lfo/amount\": ('0','100'),\n",
    "            \"volume_lfo/freq_shift\": ('0','100'),\n",
    "            \"pitch_lfo/amount\": ('0','100'),\n",
    "            \"pitch_lfo/freq_shift\": ('0','100')}\n",
    "    \n",
    "    # set up source\n",
    "    sources = Objects(data.keys())\n",
    "    sources.fromdict(data)\n",
    "    plims = {'cutoff': (0.25,0.9)}\n",
    "    sources.apply_mapping_functions(map_lims=lims, param_lims=plims)\n",
    "    \n",
    "    soni = Sonification(score, sources, generator, system)\n",
    "    soni.render()\n",
    "    dobj = soni.notebook_display(show_waveform=0.);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5928384e-7883-4a48-bd70-3d5372abdae4",
   "metadata": {},
   "source": [
    "## 4. Sonification: Spectral Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcd5691-b832-433c-b646-428d5a79bafe",
   "metadata": {},
   "source": [
    "Having covered some of these more abstract approaches, let's consider a direct _Spectral Audification_ or _\"Spectralisation\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb1992-b516-40fb-b411-94c62dc6abd7",
   "metadata": {},
   "source": [
    "We will try converting the ***periodogram*** into a ***sound spectrum*** directly, i.e. the sound has the same frequency features as the observed light curves, albeit at ***audible frequencies***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a03638-39ab-4f65-8e03-ade650f8d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in targlist:\n",
    "\n",
    "    fmin = 0.2\n",
    "    fmax = 20  \n",
    "    \n",
    "    freqs = psd[c][:,0].copy()\n",
    "    fsel = np.logical_and(freqs < fmax, freqs > fmin) \n",
    "    powers = psd[c][:,1][fsel]\n",
    "    freqs = freqs[fsel]\n",
    "\n",
    "    plt.plot(freqs, powers)\n",
    "    plt.xlabel(r'Frequency [days$^{-1}$]')\n",
    "    plt.ylabel('Power')\n",
    "    plt.title(c)\n",
    "    plt.show() \n",
    "\n",
    "    dynrange = freqs.max()/freqs.min()\n",
    "    \n",
    "    # set up spectralizer generator\n",
    "    generator = Spectralizer()\n",
    "    \n",
    "    # Lets pick the mapping frequency range for the spectrum... ‚úèÔ∏è\n",
    "    generator.modify_preset({'min_freq':100, 'max_freq':100*dynrange})\n",
    "    \n",
    "    score =  Score([['A2']], 10)\n",
    "    \n",
    "    # set up spectrum and choose some envelope parameters for fade-in and fade-out\n",
    "    maps = {'spectrum': [powers], 'pitch':[1],\n",
    "            'volume_envelope/D':[0.8],\n",
    "            'volume_envelope/S':[0.],\n",
    "            'volume_envelope/A':[0.01]}\n",
    "    \n",
    "    # again, use maximal range for the mapped parameters\n",
    "    lims = {'spectrum': ('0','100')}\n",
    "\n",
    "\n",
    "    # set up source\n",
    "    sources = Events(maps.keys())\n",
    "    sources.fromdict(maps)\n",
    "    sources.apply_mapping_functions(map_lims=lims)\n",
    "    \n",
    "    # render and play sonification!\n",
    "    soni = Sonification(score, sources, generator, system)\n",
    "    soni.render()\n",
    "    dobj = soni.notebook_display(show_waveform=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e861a6-0aac-4ce8-a3c2-d3faf46e8f5c",
   "metadata": {},
   "source": [
    "Can you hear how all these lightcurves give a different _\"timbre\"_ or _\"formant\"_?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd07798-af29-40dd-96b8-8e82f7127001",
   "metadata": {},
   "source": [
    "For some more context, we take the _\"55-Cancri\"_ curve in particular.\n",
    "\n",
    "Let's isolate the fundamental frequency of the short period variation (rapid dips) and some of it's overtones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab07e1a-3146-43cd-91ad-96d019d1c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "targ = '55Cancri'\n",
    "\n",
    "fmin = 0.2\n",
    "fmax = 20 \n",
    "\n",
    "freqs = psd[targ][:,0].copy()\n",
    "fsel = np.logical_and(freqs < fmax, freqs > fmin) \n",
    "powers = psd[targ][:,1][fsel]\n",
    "freqs = freqs[fsel]\n",
    "    \n",
    "plt.plot(freqs*(100/freqs.min()), powers)\n",
    "plt.title(targ)\n",
    "plt.xlim(100, 100*dynrange)\n",
    "# plt.axvline(115)\n",
    "\n",
    "harmonics = [660]\n",
    "cdx = 0\n",
    "for h in harmonics:\n",
    "    cdx +=1\n",
    "    for k in range(1,12):\n",
    "        plt.axvline(h*k, c=f\"C{cdx}\",ls=':')\n",
    "plt.xlabel(\"Spectral Sonification Frequency distribution [Hz]\")\n",
    "plt.ylabel(\"Power\")\n",
    "# plt.semilogx()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489a5edc-fe86-4d36-b9b9-495f83304e44",
   "metadata": {},
   "source": [
    "Turns out the dominant fundamental in _55 Cancri's_ periodogram is sonified at around 660 Hz, or an 'E5' in musical notation, lets hear that for comparison... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca1e58-e9cf-4f48-8b28-dfa6ed8be991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score =  Score([['E5']], 2)\n",
    "#score =  Score([[660.]], 2)\n",
    "\n",
    "maps = {'pitch': [1]}\n",
    "\n",
    "# specify audio system (e.g. mono, stereo, 5.1, ...)\n",
    "system = \"mono\"\n",
    "\n",
    "# set up synth (this generates the sound using mathematical waveforms)\n",
    "generator = Synthesizer()\n",
    "\n",
    "generator.load_preset('pitch_mapper')\n",
    "generator.modify_preset({\"volume_envelope\": {\"use\": \"on\", \"S\": 0., \"D\": 2}\n",
    "                        })\n",
    "\n",
    "# set up source\n",
    "sources = Objects(maps.keys())\n",
    "sources.fromdict(maps)\n",
    "sources.apply_mapping_functions(map_lims=lims)\n",
    "\n",
    "# render and play sonification!\n",
    "soni = Sonification(score, sources, generator, system)\n",
    "soni.render()\n",
    "\n",
    "soni.notebook_display(show_waveform=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f93a2ce-70a5-4d7e-994a-a8c5386bef49",
   "metadata": {},
   "source": [
    "# Bonus Material!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df5cd97-4724-4d19-9d17-967542d56ea1",
   "metadata": {},
   "source": [
    "üöß ***under construction*** üöß"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
